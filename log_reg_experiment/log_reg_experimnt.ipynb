{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Igor Sokolov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sts\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "from matplotlib import patches\n",
    "from sympy import *\n",
    "import datetime\n",
    "from functools import reduce\n",
    "from sklearn.datasets import make_spd_matrix, make_sparse_spd_matrix\n",
    "import scipy\n",
    "\n",
    "from scipy.optimize import minimize, root_scalar\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import itertools\n",
    "from scipy.special import binom\n",
    "from scipy.stats import ortho_group\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "import sklearn.metrics \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score,roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "\n",
    "from itertools import cycle\n",
    "from contextlib import redirect_stdout\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logreg_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do a dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8124,) [ 1.  1.  1. -1.  1.]\n",
      "Data shape:  (8124, 112)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python3 generate_data.py --dataset mushrooms --loss_func log-reg --homogeneous 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "python3 local_spider_homo.py --dataset mushrooms --num_workers 20 --num_local_steps 10 --batch_size 10 --continue 0 --max_it 100 --launch_number 1 --tol 1e-12\n",
      "python3 local_spider_homo.py --dataset mushrooms --num_workers 20 --num_local_steps 20 --batch_size 10 --continue 0 --max_it 100 --launch_number 1 --tol 1e-12\n",
      "python3 local_spider_homo.py --dataset mushrooms --num_workers 20 --num_local_steps 30 --batch_size 10 --continue 0 --max_it 100 --launch_number 1 --tol 1e-12\n",
      "python3 local_spider_homo.py --dataset mushrooms --num_workers 20 --num_local_steps 50 --batch_size 10 --continue 0 --max_it 100 --launch_number 1 --tol 1e-12\n",
      "python3 local_spider_homo.py --dataset mushrooms --num_workers 20 --num_local_steps 100 --batch_size 10 --continue 0 --max_it 100 --launch_number 1 --tol 1e-12\n",
      "python3 local_spider_homo.py --dataset mushrooms --num_workers 50 --num_local_steps 10 --batch_size 10 --continue 0 --max_it 100 --launch_number 1 --tol 1e-12\n",
      "python3 local_spider_homo.py --dataset mushrooms --num_workers 50 --num_local_steps 20 --batch_size 10 --continue 0 --max_it 100 --launch_number 1 --tol 1e-12\n",
      "python3 local_spider_homo.py --dataset mushrooms --num_workers 50 --num_local_steps 30 --batch_size 10 --continue 0 --max_it 100 --launch_number 1 --tol 1e-12\n",
      "python3 local_spider_homo.py --dataset mushrooms --num_workers 50 --num_local_steps 50 --batch_size 10 --continue 0 --max_it 100 --launch_number 1 --tol 1e-12\n",
      "python3 local_spider_homo.py --dataset mushrooms --num_workers 50 --num_local_steps 100 --batch_size 10 --continue 0 --max_it 100 --launch_number 1 --tol 1e-12\n",
      "python3 local_spider_homo.py --dataset mushrooms --num_workers 100 --num_local_steps 10 --batch_size 10 --continue 0 --max_it 100 --launch_number 1 --tol 1e-12\n",
      "python3 local_spider_homo.py --dataset mushrooms --num_workers 100 --num_local_steps 20 --batch_size 10 --continue 0 --max_it 100 --launch_number 1 --tol 1e-12\n",
      "python3 local_spider_homo.py --dataset mushrooms --num_workers 100 --num_local_steps 30 --batch_size 10 --continue 0 --max_it 100 --launch_number 1 --tol 1e-12\n",
      "python3 local_spider_homo.py --dataset mushrooms --num_workers 100 --num_local_steps 50 --batch_size 10 --continue 0 --max_it 100 --launch_number 1 --tol 1e-12\n",
      "python3 local_spider_homo.py --dataset mushrooms --num_workers 100 --num_local_steps 100 --batch_size 10 --continue 0 --max_it 100 --launch_number 1 --tol 1e-12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "project_path = os.getcwd() + \"/\"\n",
    "experiment_name_ar = [\"local_spider_homo\"]\n",
    "dataset_ar = [\"mushrooms\"]\n",
    "\n",
    "batch_ar = [10]\n",
    "LAUNCH_NUMBERS = 2\n",
    "launch_number_ar = np.arange (1, LAUNCH_NUMBERS)\n",
    "num_workers_ar = [20, 50, 100]\n",
    "#num_workers_ar = [20]\n",
    "num_local_steps_ar = [10, 20, 30, 50, 100 ]\n",
    "#num_local_steps_ar = [10]\n",
    "tol = 1e-12\n",
    "release = True\n",
    "max_it = 100\n",
    "is_continue = 0\n",
    "\n",
    "\n",
    "shell_script_name = \"local_spider\"\n",
    "\n",
    "with open(shell_script_name + \".sh\", 'w') as f:\n",
    "    with redirect_stdout(f):\n",
    "        #print (\"%%bash\")\n",
    "        print (\"#!/bin/bash\")\n",
    "\n",
    "        for launch_number in launch_number_ar:\n",
    "            for i, (experiment_name, dataset, num_workers, num_local_steps, batch_size ) in \\\n",
    "            enumerate (itertools.product (experiment_name_ar, dataset_ar, num_workers_ar, num_local_steps_ar, batch_ar)):\n",
    "                print (\"python3 {0}.py --dataset {1} --num_workers {2} --num_local_steps {3} --batch_size {4} --continue {5} --max_it {6} --launch_number {7} --tol {8}\".\n",
    "                format(experiment_name, dataset, num_workers, num_local_steps, batch_size , is_continue, max_it, launch_number, tol))\n",
    "\n",
    "                #show the script\n",
    "f = open(shell_script_name + \".sh\", 'r')\n",
    "print (f.read())\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-20 16:53:34\n",
      "local_spider_homo_10_20_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"local_spider_homo.py\", line 272, in <module>\n",
      "    V = sample_matrix_logreg_sgrad(W, X, y, la, i_batch) - sample_matrix_logreg_sgrad(W_prev, X, y, la, i_batch)  + V_prev # (7th)\n",
      "  File \"/Users/igorsokolov/Google_Drive/Sirius 2020/log_reg_experiment/logreg_functions.py\", line 88, in sample_matrix_logreg_sgrad\n",
      "    V[i] = sample_logreg_sgrad(W[i], X, y, la, i_batch)\n",
      "  File \"/Users/igorsokolov/Google_Drive/Sirius 2020/log_reg_experiment/logreg_functions.py\", line 73, in sample_logreg_sgrad\n",
      "    return np.sum(logreg_sgrad(w, X[i_batch], y[i_batch], la))/len(i_batch) + la * regularizer_grad(w)\n",
      "  File \"/Users/igorsokolov/Google_Drive/Sirius 2020/log_reg_experiment/logreg_functions.py\", line 48, in logreg_sgrad\n",
      "    loss_sgrad = - y_i * x_i / (1 + np.exp(y_i * np.dot(x_i, w)))\n",
      "ValueError: operands could not be broadcast together with shapes (10,) (10,112) \n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'b'\\nbash local_spider.sh\\n'' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-53da784d9a86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\nbash local_spider.sh\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2350\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2352\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2353\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</Users/igorsokolov/anaconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-110>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'\\nbash local_spider.sh\\n'' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "bash local_spider.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload whole data \n",
    "def export_legend(legend, filename=\"legend.pdf\", expand=[-5,-5,5,5]):\n",
    "    fig  = legend.figure\n",
    "    fig.canvas.draw()\n",
    "    bbox  = legend.get_window_extent()\n",
    "    bbox = bbox.from_extents(*(bbox.extents + np.array(expand)))\n",
    "    bbox = bbox.transformed(fig.dpi_scale_trans.inverted())\n",
    "    fig.savefig(filename, dpi=\"figure\", bbox_inches=bbox)\n",
    "\n",
    "project_path = os.getcwd() + \"/\"\n",
    "\n",
    "\n",
    "experiment_name_ar = [\"local_spider_homo\"]\n",
    "dataset_ar = [\"mushrooms\"]\n",
    "loss_func = \"log-reg\"\n",
    "batch_ar = [10]\n",
    "LAUNCH_NUMBERS = 2\n",
    "launch_number_ar = np.arange (1, LAUNCH_NUMBERS)\n",
    "#num_workers_ar = [20, 50, 100]\n",
    "num_workers_ar = [20]\n",
    "#num_local_steps_ar = [10, 20, 30, 50, 100 ]\n",
    "num_local_steps_ar = [10]\n",
    "tol = 1e-12\n",
    "release = True\n",
    "max_it = 100\n",
    "is_continue = 0\n",
    "\n",
    "\n",
    "w_init = {}\n",
    "la_ar = {}\n",
    "info_num_ar = {}\n",
    "loss_ar = {}\n",
    "epochs_ar = {}\n",
    "its_ar = {}\n",
    "w_ar = {}\n",
    "label_ar = {}\n",
    "experiments = []\n",
    "for i, (experiment_name, dataset, num_workers, num_local_steps, batch_size ) in \\\n",
    "            enumerate (itertools.product (experiment_name_ar, dataset_ar, num_workers_ar, num_local_steps_ar, batch_ar)):\n",
    "     \n",
    "    \n",
    "    \"\"\"\n",
    "    if experiment in experiments: \n",
    "        continue\n",
    "    else:\n",
    "        experiments.append(experiment)\n",
    "    \"\"\"\n",
    "    \n",
    "    id_str = \"{0}_{1}\".format(dataset, experiment)#####\n",
    "    id_func = \"{0}_{1}\".format(dataset, loss_func)#####\n",
    "    id_dataset = \"{0}\".format(dataset)#####\n",
    "    \n",
    "    \n",
    "    logs_path = project_path + \"logs/logs1_{0}_{1}/\".format(dataset, experiment)\n",
    "    data_path = project_path + \"data_{0}/\".format(dataset)\n",
    "    plot_path = project_path + \"plot_{0}/\".format(dataset)\n",
    "    \n",
    "    if os.path.exists(plot_path) == False:\n",
    "        os.mkdir(plot_path)\n",
    "    \n",
    "    if os.path.isfile(data_path + 'data_info.npy'): \n",
    "        data_info = np.load(data_path + 'data_info.npy')\n",
    "        N, L = data_info[:2]    \n",
    "    else:\n",
    "        raise ValueError(\"cannot load data_info.npy\")\n",
    "\n",
    "    if os.path.isfile(logs_path + 'norms' + \"_\" + experiment + \".npy\"):\n",
    "        f_grad_norms = np.load(logs_path + 'norms' + '_' + experiment + \".npy\")\n",
    "    else:\n",
    "        raise ValueError(\"cannot load norms info\")\n",
    "\n",
    "    if os.path.isfile(logs_path + 'communication' + \"_\" + experiment + \".npy\"):\n",
    "        its_comm = np.load(logs_path + 'communication' + '_' + experiment + \".npy\")\n",
    "    else:\n",
    "        raise ValueError(\"cannot load communication info\")\n",
    "\n",
    "    return w_0, list(loss), list(f_grad_norms), list(its_comm), list(epochs)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if os.path.isfile(logs_path + 'loss' + \"_\" + experiment + \".npy\"):\n",
    "        loss_ar[id_str] = np.load(logs_path + 'loss' + '_' + experiment + \".npy\")\n",
    "        #print(id_str, loss_ar[id_str].shape)\n",
    "    else:\n",
    "        print(id_str)\n",
    "        raise ValueError(\"cannot load loss info\")\n",
    "        \n",
    "        \n",
    "    if os.path.isfile(logs_path + 'epochs' + \"_\" + experiment + \".npy\"):\n",
    "        epochs_ar[id_str] = np.load(logs_path + 'epochs' + '_' + experiment + \".npy\")\n",
    "    else:\n",
    "        raise ValueError(\"cannot load epochs info\")\n",
    "        \n",
    "    if os.path.isfile(logs_path + 'time' + \"_\" + experiment + \".npy\"):\n",
    "        time_ar[id_str]        = np.load(logs_path + 'time' + '_' + experiment + \".npy\")\n",
    "    else:\n",
    "        raise ValueError(\"cannot load time info\")\n",
    "    \n",
    "    if os.path.isfile(logs_path + 'iteration' + \"_\" + experiment + \".npy\"):\n",
    "        its_ar[id_str] = np.load(logs_path + 'iteration' + '_' + experiment + \".npy\")\n",
    "    else:\n",
    "        raise ValueError(\"cannot load iteration info\")\n",
    "    \n",
    "    #print (label)\n",
    "    label_ar[id_label] = label\n",
    "    \n",
    "keys = list (label_ar.keys())\n",
    "#print (len(keys))\n",
    "\n",
    "values_all_posible = [\"o\",\"*\",\"v\",\"^\",\"<\",\">\",\"s\",\"p\",\"P\",\"h\",\"H\",\"+\",\"x\",\"X\",\"D\",\"d\",\"|\",\"_\"]\n",
    "len_batch_ar = len(batch_ar)\n",
    "n_experiments_per_plot = int(len(experiments)/len_batch_ar)\n",
    "values = values_all_posible[:n_experiments_per_plot]\n",
    "values = reduce(lambda x,y: x + y, [[values[i]] * len_batch_ar for i in range(len(values))])\n",
    "\n",
    "marker_ar = dict(zip(keys, values))\n",
    "\n",
    "colors_all_posible = ['blue', 'red', 'orange','aqua','violet', 'darkorange', \n",
    "          'cornflowerblue', 'darkgreen', \n",
    "          'coral', 'lime',  \n",
    "          'darkgreen', 'goldenrod','maroon',\n",
    "          'black', 'brown', 'yellowgreen'\n",
    "         ]\n",
    "\n",
    "colors = colors_all_posible[:n_experiments_per_plot]\n",
    "colors = reduce(lambda x,y: x + y, [[colors[i]] * len_batch_ar for i in range(len(colors))])\n",
    "\n",
    "color_ar = dict(zip(keys, colors))\n",
    "\n",
    "#what dow you want to show in the plot   \n",
    "\n",
    "colors = ['blue', 'red', 'orange','aqua','violet', 'darkorange', \n",
    "          'cornflowerblue', 'darkgreen', \n",
    "          'coral', 'lime',  \n",
    "          'darkgreen', 'goldenrod','maroon',\n",
    "          'black', 'brown', 'yellowgreen'\n",
    "         ]\n",
    "\n",
    "tol = 1e-8\n",
    "x_axis = \"iter\"\n",
    "\n",
    "\n",
    "n_iter_ar = {}\n",
    "n_iter_time_ar = {} #here I store x_axis for time = time in sec\n",
    "for j, batch in enumerate (batch_ar):\n",
    "    n_iter = []\n",
    "    n_iter_time = []\n",
    "    for i, (experiment_name, dataset, loss_func, sampling_kind, step_type) in \\\n",
    "        enumerate (itertools.product (experiment_name_ar, dataset_ar, loss_func_ar, sampling_kind_ar, step_type_ar)):\n",
    "        if (loss_func == \"log-reg\" and dataset in [\"quad_1\", \"quad_2\"]) or (loss_func == \"quadratic\" and dataset == \"mushrooms\"):\n",
    "            continue\n",
    "        if (sampling_kind == \"uniform\" and (step_type not in [\"uniform\", \"optimal\"] )):\n",
    "            continue\n",
    "        if ((sampling_kind == \"importance_cd\" or sampling_kind == \"importance_acd\") and (step_type not in [\"arbitrary\", \"optimal\"])):\n",
    "            continue\n",
    "        if (experiment_name[:2] == \"LS\"):\n",
    "            experiment = '{0}_{1}_{2}_{3}'.format(experiment_name, loss_func, sampling_kind, batch)\n",
    "            id_label = \"{0}_{1}_{2}\".format(experiment_name, sampling_kind, batch)\n",
    "        elif (experiment_name[:5] == \"NSYNC\"):\n",
    "            experiment = '{0}_{1}_{2}_{3}_{4}'.format(experiment_name, loss_func, sampling_kind, step_type, batch)\n",
    "            id_label = \"{0}_{1}_{2}_{3}\".format(experiment_name, sampling_kind, step_type, batch)\n",
    "        else:\n",
    "            raise ValueError(\"wrong experiment_name\")\n",
    "        id_str = \"{0}_{1}\".format(dataset, experiment)#####    \n",
    "        n_iter.append(its_ar[id_str].shape[0])\n",
    "        time_ar[id_str] += t_init_ar[id_str]\n",
    "        #print (experiment, t_init_ar[id_str])\n",
    "        n_iter_time.append(time_ar[id_str][-1])\n",
    "        \n",
    "    n_iter_ar[batch] = int (1.2 * min(n_iter))\n",
    "    n_iter_time_ar[batch] = 1.2 * min(n_iter_time)\n",
    "\n",
    "experiments = []\n",
    "fig = plt.figure()\n",
    "    \n",
    "####################################################################################################################################################################################\n",
    "legend_data = []\n",
    "line_labels = []\n",
    "marker_size = 40\n",
    "    \n",
    "for j, batch in enumerate (batch_ar):\n",
    "    for i, (experiment_name, dataset, loss_func, sampling_kind, step_type) in \\\n",
    "        enumerate (itertools.product (experiment_name_ar, dataset_ar, loss_func_ar, sampling_kind_ar, step_type_ar)):\n",
    "        \n",
    "        if (loss_func == \"log-reg\" and dataset in [\"quad_1\", \"quad_2\"]) or (loss_func == \"quadratic\" and dataset == \"mushrooms\"):\n",
    "            continue\n",
    "        if (sampling_kind == \"uniform\" and (step_type not in [\"uniform\", \"optimal\"] )):\n",
    "            continue\n",
    "        if ((sampling_kind == \"importance_cd\" or sampling_kind == \"importance_acd\") and (step_type not in [\"arbitrary\", \"optimal\"])):\n",
    "            continue\n",
    "            \n",
    "        #print (experiment_name, dataset, loss_func, sampling_kind, step_type, batch)\n",
    "    \n",
    "        if (experiment_name[:2] == \"LS\"):\n",
    "            experiment = '{0}_{1}_{2}_{3}'.format(experiment_name, loss_func, sampling_kind, batch)\n",
    "            id_label = \"{0}_{1}_{2}\".format(experiment_name, sampling_kind, batch)\n",
    "        elif (experiment_name[:5] == \"NSYNC\"):\n",
    "            experiment = '{0}_{1}_{2}_{3}_{4}'.format(experiment_name, loss_func, sampling_kind, step_type, batch)\n",
    "            id_label = \"{0}_{1}_{2}_{3}\".format(experiment_name, sampling_kind, step_type, batch)\n",
    "        else:\n",
    "            raise ValueError(\"wrong experiment_name\")\n",
    "        \n",
    "        if experiment in experiments: \n",
    "            continue\n",
    "        else:\n",
    "            experiments.append(experiment)\n",
    "        \n",
    "        id_str = \"{0}_{1}\".format(dataset, experiment)#####\n",
    "        id_func = \"{0}_{1}\".format(dataset, loss_func)#####\n",
    "        id_dataset = \"{0}\".format(dataset)#####\n",
    "        \n",
    "        if x_axis == \"epochs\":\n",
    "            plt.xlabel('epochs')\n",
    "            if  ((id_str in epochs_ar) and id_str in loss_ar):\n",
    "                loss_f_min = loss_ar[id_str] - f_min_ar[id_func]\n",
    "                \n",
    "                if (experiment_name[:2] == \"LS\"):\n",
    "                    markers_on = np.unique(epochs_ar[id_str].astype(int))\n",
    "                    markers_on = its_ar[id_str][its_ar[id_str]%20000==0 ]\n",
    "\n",
    "                elif (experiment_name[:5] == \"NSYNC\"):       \n",
    "                    markers_on = its_ar[id_str][its_ar[id_str]%1000==0 ]\n",
    "                else:\n",
    "                    raise ValueError(\"wrong experiment_name\")\n",
    "                    \n",
    "                #markers_on = its_ar[id_str][its_ar[id_str]%(int(n_iter/20))==0 ]\n",
    "                #print (markers_on)\n",
    "                plt.plot(epochs_ar[id_str], loss_f_min, color=color_ar[id_label], marker=marker_ar[id_label], markersize=marker_size, markevery=list(markers_on), label= label_ar[id_label])\n",
    "            else:\n",
    "                raise ValueError(\"can not plot\")\n",
    "        elif x_axis == \"iter\":\n",
    "            plt.xlabel('iterations')\n",
    "            if  ((id_str in its_ar) and id_str in loss_ar):\n",
    "                #print (1)\n",
    "                loss_f_min = loss_ar[id_str] - f_min_ar[id_func]\n",
    "                \n",
    "                #loss_f_min = loss_f_min[loss_f_min > 0] \n",
    "                #its_ar[id_str] = its_ar[id_str][:loss_f_min.shape[0]]\n",
    "                #its_ar[id_str] = its_ar[id_str][:n_iter_ar[batch]]\n",
    "                loss_f_min = loss_f_min[:its_ar[id_str].shape[0]]\n",
    "                \n",
    "                markers_on = its_ar[id_str][its_ar[id_str]%(int (len(its_ar[id_str][:-(1+2*i)])/10) )==0 ]\n",
    "                    \n",
    "                #print (id_str, its_ar[id_str].shape, loss_f_min.shape, loss_f_min[-3:])\n",
    "                #print (its_ar[id_str].shape, markers_on)\n",
    "                legend_data.append (plt.plot(its_ar[id_str], loss_f_min, color=color_ar[id_label], marker=marker_ar[id_label], markersize=marker_size, markevery=list(markers_on), label= label_ar[id_label])[0])\n",
    "                line_labels.append (label_ar[id_label])\n",
    "            else:\n",
    "                raise ValueError(\"can not plot\")\n",
    "        elif x_axis == \"time\":\n",
    "            plt.xlabel('time, sec')\n",
    "            if  ((id_str in time_ar) and id_str in loss_ar):\n",
    "                loss_f_min = loss_ar[id_str] - f_min_ar[id_func]\n",
    "                \n",
    "                #loss_f_min = loss_f_min[loss_f_min > tol]\n",
    "                time_ar[id_str] = time_ar[id_str][time_ar[id_str] <= n_iter_time_ar[batch]]\n",
    "                loss_f_min = loss_f_min[:time_ar[id_str].shape[0]]\n",
    "                its_ar[id_str] = its_ar[id_str][:time_ar[id_str].shape[0]]\n",
    "                \n",
    "                markers_on = its_ar[id_str][its_ar[id_str]%(int (len(its_ar[id_str][:-1])/10) )==0 ]\n",
    "                \n",
    "                #print (id_str, its_ar[id_str].shape, markers_on)\n",
    "                #print (id_str, its_ar[id_str].shape, loss_f_min.shape, loss_f_min[-3:])\n",
    "                \n",
    "                plt.plot(time_ar[id_str], loss_f_min, color=color_ar[id_label], marker=marker_ar[id_label], markersize=marker_size, markevery=list(markers_on), \n",
    "                         label=label_ar[id_label])\n",
    "            else:\n",
    "                raise ValueError(\"can not plot\")\n",
    "        else:\n",
    "            ValueError(\"wrong x_axis\")\n",
    "\n",
    "\n",
    "    #epoch = epochs_ar[\"mushrooms_LS_non-scaled_log-reg_importance_acd_{0}\".format(5)]\n",
    "    #plt.xticks(np.arange(np.int(min(epoch)), \n",
    "     #            np.int(max(epoch))+1, 5))\n",
    "    #plt.subplot(2, 2, j+1)\n",
    "    #print(j)\n",
    "    plt.rcParams[\"figure.figsize\"] = [26,20]\n",
    "    if j ==0: \n",
    "        plt.ylabel(r\"$f(x) - f(x^*)$\")\n",
    "    \n",
    "    size = 140\n",
    "    title = r\"${0}$\".format(loss_func)\n",
    "    plt.rcParams['font.family'] = 'serif'\n",
    "    plt.rcParams['font.serif'] = 'FreeSerif'\n",
    "    plt.rcParams['lines.linewidth'] = 4\n",
    "    #plt.rcParams['lines.markersize'] = 10\n",
    "    plt.rcParams['xtick.labelsize'] = size#40\n",
    "    plt.rcParams['ytick.labelsize'] = size#40\n",
    "    plt.rcParams['legend.fontsize'] = size#30\n",
    "    \n",
    "    plt.rcParams['axes.titlesize'] = size#40\n",
    "    plt.rcParams['axes.labelsize'] = size#40\n",
    "    #plt.rcParams[\"figure.figsize\"] = [13,9]\n",
    "    plt.yscale('log')\n",
    "    #plt.xscale('log')\n",
    "    plt.title(r\"$\\tau = {0}; {1}$\".format(batch, dataset))\n",
    "    plt.ticklabel_format(axis='x', style='sci', scilimits=(1, 4))\n",
    "    #\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    legend = plt.legend(loc=\"lower center\", framealpha=0.5, ncol=3, bbox_to_anchor=(0.45, -1.2))\n",
    "    plt.savefig(plot_path + \"{0}_{1}_{2}_{3}_{4}_{5}.pdf\".format('-'.join(experiment_name_ar), '-'.join(sampling_kind_ar),'-'.join(step_type_ar), x_axis, loss_func, batch))\n",
    "    plt.show()\n",
    "    #plt.savefig(plot_path + \"{0}_{1}_{2}_{3}.pdf\".format('-'.join(experiment_name_ar), x_axis, loss_func, batch))\n",
    "export_legend(legend)\n",
    "    \n",
    "#plt.savefig(plot_path + \"{0}_{1}_{2}.pdf\".format('-'.join(experiment_name_ar), x_axis, loss_func))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
