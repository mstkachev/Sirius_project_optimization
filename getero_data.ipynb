{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from numpy.random import normal, uniform\n",
    "from sklearn.datasets import make_spd_matrix, make_sparse_spd_matrix, load_svmlight_file, dump_svmlight_file\n",
    "from numpy.linalg import norm\n",
    "\n",
    "from logreg_functions import *\n",
    "\n",
    "import sys\n",
    "\n",
    "import itertools\n",
    "from scipy.special import binom\n",
    "from scipy.stats import ortho_group\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_svmlight_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_workers = 89\n",
    "#Ткачев М. разделение двуклассового датасета на гетерогенные части по рабочим\n",
    "RAW_DATA_PATH = os.getcwd() + \"/mushrooms.txt\"#если загрузка данных была ранее, закомментить строку\n",
    "data, labels = load_svmlight_file(RAW_DATA_PATH)#если загрузка данных была ранее, закомментить строку\n",
    "data_dense = data.todense()\n",
    "enc_labels = labels.copy()\n",
    "min_label = min(np.unique(enc_labels))\n",
    "max_label = max(np.unique(enc_labels))\n",
    "enc_labels[enc_labels == min_label] = -1\n",
    "enc_labels[enc_labels == max_label] = 1\n",
    "A = data_dense[np.where(enc_labels == - 1)]\n",
    "B = data_dense[np.where(enc_labels == 1)]\n",
    "K = n_workers #количество рабочих, заменить имя справа, если я не угадал\n",
    "C = []\n",
    "z = np.zeros((0, data_dense.shape[1]))          \n",
    "for i in range(K):\n",
    "    C.append(z)\n",
    "h = 2 * A.shape[0] / ((K - 1) * K)\n",
    "h = max(int(h), 1)\n",
    "hh = 2 * B.shape[0] / ((K - 1) * K)\n",
    "hh = max(int(hh), 1)\n",
    "for i in range(1, K - 1):\n",
    "    C[i] = np.vstack((C[i], A[int((h * i * (i - 1) / 2)) : int((h * i * (i + 1) /2))]))\n",
    "    C[-i-1] = np.vstack((C[-i-1], B[int((hh * i * (i - 1) / 2)) : int((hh * i * (i + 1) /2))]))\n",
    "C[K-1] = np.vstack((C[K-1], A[int((h * (K - 1) * (K - 2) / 2)):]))\n",
    "C[0] = np.vstack((C[0], B[int((hh * (K - 1) * (K - 2) / 2)):]))\n",
    "list(map(np.random.shuffle, C))\n",
    "#в идеале, для +- одинаковой размерности нужно раскинуть остаток равномерно по рабочим,\n",
    "#однако этот подход нарушает гетерогенность в случае большого числа рабочих,\n",
    "#так как в разбиении получается очень близкое количество данных одного класса в частях\n",
    "#поэтому мы допускаем, что большой накопившийся остаток уходит крайним рабочим,\n",
    "#что может сильно увеличить размер их части данных относительно остальных,\n",
    "#но не испортит гетерогенность данных\n",
    "#оптимальное крайнее число рабочих для датасета mushrooms -- 89\n",
    "#с таким числом данные разбиваются на практически одинаковые по размеру\n",
    "#гетерогенные части\n",
    "#ниже написана проверка размерности и сводка по рабочим\n",
    "#for i in range(0, K):\n",
    "#    print(\"worker \",i, C[i].shape[0])\n",
    "#print(C[0].shape[0] - C[1].shape[0])\n",
    "#print(C[1].shape[0] - C[2].shape[0])\n",
    "#S = 0\n",
    "#for i in range(0, K):\n",
    "#    S = S + C[i].shape[0]\n",
    "#print(S)\n",
    "#print(A.shape[0])\n",
    "#print(B.shape[0])\n",
    "#print(data_dense.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
